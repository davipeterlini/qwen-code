# üìä Guia Completo de Benchmark - Qwen Code CLI vs Claude Code

> **Vers√£o:** 2.0.0
> **√öltima atualiza√ß√£o:** Fevereiro de 2026
> **Objetivo:** Comparar performance e qualidade entre Qwen Code (aplica√ß√£o buildada) e Claude Code CLI executando testes diretamente no terminal

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Prepara√ß√£o do Ambiente](#prepara√ß√£o-do-ambiente)
3. [Metodologia de Benchmark](#metodologia-de-benchmark)
4. [Suite de Testes R√°pidos](#suite-de-testes-r√°pidos)
5. [Executando os Testes](#executando-os-testes)
6. [M√©tricas de Avalia√ß√£o](#m√©tricas-de-avalia√ß√£o)
7. [Planilha de Resultados](#planilha-de-resultados)
8. [An√°lise Comparativa](#an√°lise-comparativa)

---

## Vis√£o Geral

### üéØ Objetivos do Benchmark

Este guia fornece metodologia pr√°tica para comparar **diretamente no terminal**:

| CLI             | Comando                              | Descri√ß√£o                                       |
| --------------- | ------------------------------------ | ----------------------------------------------- |
| **Qwen Code**   | `node dist/cli.js` ou `npm run qwen` | Aplica√ß√£o Qwen buildada (desenvolvimento local) |
| **Claude Code** | `claude`                             | CLI da Anthropic (refer√™ncia de mercado)        |

**O que avaliar:**

1. **Qualidade de C√≥digo** - Corre√ß√£o, legibilidade, melhores pr√°ticas
2. **Tempo de Resposta** - Velocidade de gera√ß√£o
3. **Experi√™ncia do Usu√°rio** - Fluxo de trabalho, ergonomia
4. **Recursos Avan√ßados** - Hooks, Skills, MCP, Subagents

### üöÄ Abordagem Simplificada

Ao inv√©s de testes complexos, este guia foca em:

- ‚úÖ **Testes diretos no terminal** - Use `node dist/cli.js` e `claude` diretamente
- ‚úÖ **Prompts r√°pidos** - Testes de 1-5 minutos cada
- ‚úÖ **Compara√ß√£o lado a lado** - Mesmo prompt, ambas CLIs
- ‚úÖ **Avalia√ß√£o subjetiva** - Sua percep√ß√£o de qualidade

### üìä Comparativo Direto

```bash
# Exemplo de teste comparativo
node dist/cli.js "Crie uma fun√ß√£o TypeScript que valide emails"
claude "Create a TypeScript function that validates emails"
```

### ‚ö†Ô∏è Importante: Condi√ß√µes Justas

Para garantir comparativo **justo e real**:

- ‚úÖ **Mesmo projeto** de teste (diret√≥rio limpo)
- ‚úÖ **Mesmos prompts** (traduzidos quando necess√°rio)
- ‚úÖ **Mesmo contexto** inicial (zero-state, sem hist√≥rico)
- ‚úÖ **Mesmas condi√ß√µes** de rede/hardware

---

## Prepara√ß√£o do Ambiente

### üñ•Ô∏è Requisitos M√≠nimos

| Componente   | Requisito               |
| ------------ | ----------------------- |
| **Node.js**  | >= 20.0.0               |
| **npm**      | >= 9.0.0                |
| **Git**      | Qualquer vers√£o recente |
| **Terminal** | bash, zsh, ou similar   |

### üì¶ Instala√ß√£o das CLIs

#### 1. Qwen Code (Aplica√ß√£o Buildada)

```bash
# No diret√≥rio do projeto qwen-code
npm install

# Build da aplica√ß√£o
npm run build

# Verificar build
ls -la dist/cli.js

# Opcional: criar alias para facilitar
alias qwen="node $(pwd)/dist/cli.js"

# Verificar instala√ß√£o
node dist/cli.js --version
```

#### 2. Claude Code CLI

```bash
# Instalar globalmente
npm install -g @anthropic-ai/claude-code

# Ou usar npx (sem instala√ß√£o permanente)
npx @anthropic-ai/claude-code --version

# Verificar instala√ß√£o
claude --version
```

### üîß Setup do Projeto de Teste

#### Criar Diret√≥rio de Benchmark

```bash
# Criar diret√≥rio limpo para testes
mkdir -p ~/benchmark-cli
cd ~/benchmark-cli

# Inicializar projeto Node.js
npm init -y

# Criar estrutura b√°sica
mkdir -p src tests
```

#### Estrutura Recomendada

```
benchmark-cli/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ (c√≥digo gerado pelos testes)
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ (testes gerados)
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README.md
```

#### Limpar Antes de Cada Teste

```bash
# Script de limpeza (executar antes de cada teste)
rm -rf src/* tests/*
git clean -fdx  # Remove todos arquivos n√£o versionados
```

---

## Metodologia de Benchmark

### üìê Abordagem Simplificada

Cada teste segue o padr√£o:

```
1. Limpar diret√≥rio (git clean -fdx)
2. Executar prompt no Qwen (node dist/cli.js)
3. Cronometrar tempo (time command ou percep√ß√£o)
4. Salvar resultado
5. Limpar diret√≥rio
6. Executar mesmo prompt no Claude
7. Comparar resultados
```

### üéØ Crit√©rios de Avalia√ß√£o

#### 1. **Corre√ß√£o Funcional** (0-10)

| Nota | Crit√©rio                      |
| ---- | ----------------------------- |
| 10   | Funciona perfeitamente        |
| 8-9  | Funciona, pequenos ajustes    |
| 6-7  | Funciona parcialmente         |
| 4-5  | Requer ajustes significativos |
| 0-3  | N√£o funciona                  |

#### 2. **Qualidade de C√≥digo** (0-10)

| Nota | Crit√©rio                       |
| ---- | ------------------------------ |
| 10   | Production-ready, testes, docs |
| 8-9  | Bom c√≥digo, precisa de testes  |
| 6-7  | C√≥digo aceit√°vel               |
| 4-5  | C√≥digo fraco                   |
| 0-3  | C√≥digo inutiliz√°vel            |

#### 3. **Consumo de Tokens** (m√©tricas reais)

| M√©trica              | Descri√ß√£o                     | Como medir                    |
| -------------------- | ----------------------------- | ----------------------------- |
| **Tokens de Input**  | Tokens enviados na requisi√ß√£o | Output da CLI ou logs         |
| **Tokens de Output** | Tokens gerados na resposta    | Output da CLI ou logs         |
| **Total de Tokens**  | Input + Output                | Soma das m√©tricas             |
| **Custo Estimado**   | Pre√ßo da requisi√ß√£o           | Calculado com base nos tokens |

#### 4. **Tempo de Resposta** (segundos)

| Nota | Tempo  |
| ---- | ------ |
| 10   | < 5s   |
| 8-9  | 5-10s  |
| 6-7  | 10-20s |
| 4-5  | 20-40s |
| 0-3  | > 40s  |

#### 5. **Experi√™ncia do Usu√°rio** (0-10)

| Nota | Crit√©rio                    |
| ---- | --------------------------- |
| 10   | Fluxo perfeito, zero atrito |
| 8-9  | Bom fluxo, minor atritos    |
| 6-7  | Fluxo aceit√°vel             |
| 4-5  | Fluxo problem√°tico          |
| 0-3  | Fluxo quebrado              |

### üìä F√≥rmula de Score Final

```
Score = (Corre√ß√£o √ó 0.25) +
        (Qualidade √ó 0.25) +
        (Efici√™ncia Tokens √ó 0.20) +
        (Tempo Normalizado √ó 0.15) +
        (UX √ó 0.15)

Onde:
- Tempo Normalizado = max(0, 10 - (tempo_segundos / 5))
- Efici√™ncia Tokens = 10 - ((total_tokens - baseline) / baseline √ó 5)
```

### üîç Como Medir Tokens

#### Qwen Code (node dist/cli.js)

```bash
# Habilitar logs detalhados
export DEBUG=qwen*
node dist/cli.js "<prompt>" 2>&1 | grep -E "(tokens|usage|input|output)"

# Ou verificar output direto (algumas CLIs mostram no final)
node dist/cli.js "<prompt>"
```

#### Claude Code

```bash
# Claude Code geralmente mostra tokens no output
claude "<prompt>"

# Ou usar verbose mode
claude "<prompt>" --verbose
```

#### Script para Extrair Tokens

```bash
#!/bin/bash
# extract-tokens.sh

OUTPUT_FILE=$1

# Extrair tokens de input
INPUT_TOKENS=$(grep -oP 'input tokens: \K\d+' $OUTPUT_FILE || echo 0)

# Extrair tokens de output
OUTPUT_TOKENS=$(grep -oP 'output tokens: \K\d+' $OUTPUT_FILE || echo 0)

# Total
TOTAL=$((INPUT_TOKENS + OUTPUT_TOKENS))

echo "Input: $INPUT_TOKENS tokens"
echo "Output: $OUTPUT_TOKENS tokens"
echo "Total: $TOTAL tokens"

# Calcular custo estimado (exemplo: $0.0001/1K input, $0.0003/1K output)
COST=$(echo "scale=6; ($INPUT_TOKENS * 0.0001 + $OUTPUT_TOKENS * 0.0003) / 1000" | bc)
echo "Custo estimado: \$${COST}"
```

---

## Suite de Testes R√°pidos

### üß™ Como Usar

Cada teste deve ser executado **primeiro no Qwen (buildado)**, depois no `claude`.

**Template de execu√ß√£o:**

```bash
# 0. Ir para diret√≥rio do qwen-code (para usar dist/cli.js)
cd /path/to/qwen-code

# 1. Limpar ambiente de teste
cd ~/benchmark-cli && git clean -fdx

# 2. Executar no Qwen (cronometre e capture tokens)
time node /path/to/qwen-code/dist/cli.js "<PROMPT>" 2>&1 | tee qwen-output-test-01.txt

# 3. Extrair tokens do output
./scripts/extract-tokens.sh qwen-output-test-01.txt

# 4. Salvar resultado
cp -r src qwen-result-test-01

# 5. Limpar e executar no Claude
git clean -fdx
time claude "<PROMPT>" 2>&1 | tee claude-output-test-01.txt

# 6. Extrair tokens do output
./scripts/extract-tokens.sh claude-output-test-01.txt

# 7. Salvar resultado
cp -r src claude-result-test-01

# 8. Comparar
diff -r qwen-result-test-01 claude-result-test-01
```

### üõ†Ô∏è Script de Automa√ß√£o com Tokens

Crie um script para facilitar:

```bash
#!/bin/bash
# benchmark.sh

QWEN_CLI="/path/to/qwen-code/dist/cli.js"
BENCHMARK_DIR=~/benchmark-cli
RESULTS_DIR=~/benchmark-results/$(date +%Y%m%d-%H%M%S)

mkdir -p $RESULTS_DIR

run_test() {
  local test_num=$1
  local prompt=$2

  echo "üß™ Teste $test_num: $prompt"

  # Limpar
  cd $BENCHMARK_DIR && git clean -fdx

  # Qwen
  echo "‚è≥ Executando Qwen..."
  START_TIME=$(date +%s.%N)
  node $QWEN_CLI "$prompt" 2>&1 | tee $RESULTS_DIR/qwen-test-$test_num.txt
  END_TIME=$(date +%s.%N)
  QWEN_TIME=$(echo "$END_TIME - $START_TIME" | bc)

  # Extrair tokens Qwen
  ./scripts/extract-tokens.sh $RESULTS_DIR/qwen-test-$test_num.txt > $RESULTS_DIR/qwen-tokens-$test_num.txt

  # Salvar c√≥digo
  cp -r src $RESULTS_DIR/qwen-code-$test_num

  # Limpar
  git clean -fdx

  # Claude
  echo "‚è≥ Executando Claude..."
  START_TIME=$(date +%s.%N)
  claude "$prompt" 2>&1 | tee $RESULTS_DIR/claude-test-$test_num.txt
  END_TIME=$(date +%s.%N)
  CLAUDE_TIME=$(echo "$END_TIME - $START_TIME" | bc)

  # Extrair tokens Claude
  ./scripts/extract-tokens.sh $RESULTS_DIR/claude-test-$test_num.txt > $RESULTS_DIR/claude-tokens-$test_num.txt

  # Salvar c√≥digo
  cp -r src $RESULTS_DIR/claude-code-$test_num

  # Registrar m√©tricas
  echo "$test_num,$QWEN_TIME,$CLAUDE_TIME" >> $RESULTS_DIR/metrics.csv

  echo "‚úÖ Teste $test_num completo!"
  echo "   Qwen: ${QWEN_TIME}s"
  echo "   Claude: ${CLAUDE_TIME}s"
}

# Exemplo de uso
# run_test 1 "Crie uma fun√ß√£o TypeScript que valide emails"
```

---

### üß™ Teste 1: Valida√ß√£o de Email (B√°sico)

**Tempo estimado:** 1-2 minutos

**Prompt (Qwen):**

```
Crie uma fun√ß√£o TypeScript que valide emails.
A fun√ß√£o deve:
1. Verificar formato b√°sico (texto@texto.texto)
2. Retornar boolean
3. Incluir JSDoc
4. Exportar a fun√ß√£o

Nome: validateEmail
Arquivo: src/validateEmail.ts
```

**Prompt (Claude):**

```
Create a TypeScript function that validates emails.
Requirements:
1. Check basic format (text@text.text)
2. Return boolean
3. Include JSDoc
4. Export the function

Name: validateEmail
File: src/validateEmail.ts
```

**Crit√©rios:**

- ‚úÖ Regex funcional
- ‚úÖ Tipagem correta
- ‚úÖ Documenta√ß√£o JSDoc
- ‚úÖ Exporta√ß√£o correta

---

### üß™ Teste 2: Refatora√ß√£o (Intermedi√°rio)

**Tempo estimado:** 2-3 minutos

**Prompt (Qwen):**

````
Refatore esta fun√ß√£o para melhorar performance e legibilidade:

```typescript
function processData(data) {
  var result = [];
  for (var i = 0; i < data.length; i++) {
    if (data[i].active == true) {
      var item = data[i];
      item.processed = true;
      result.push(item);
    }
  }
  return result;
}
````

Use TypeScript, tipos adequados, e m√©todos funcionais.
Arquivo: src/processData.ts

```

**Prompt (Claude):**
```

Refactor this function for better performance and readability:

[Paste same code]

Use TypeScript, proper types, and functional methods.
File: src/processData.ts

```

**Crit√©rios:**
- ‚úÖ Convers√£o para TypeScript
- ‚úÖ Uso de filter/map
- ‚úÖ Tipos adequados
- ‚úÖ Imutabilidade

---

### üß™ Teste 3: Componente React (Intermedi√°rio)

**Tempo estimado:** 3-5 minutos

**Prompt (Qwen):**
```

Crie um componente React funcional TypeScript para login.

Requisitos:

1. Campos: email, senha
2. Valida√ß√£o em tempo real
3. Estado de loading
4. Tratamento de erros
5. Use hooks (useState, useEffect)

Exporte como: src/LoginForm.tsx

```

**Prompt (Claude):**
```

Create a TypeScript React functional component for login.

Requirements:

1. Fields: email, password
2. Real-time validation
3. Loading state
4. Error handling
5. Use hooks (useState, useEffect)

Export as: src/LoginForm.tsx

```

**Crit√©rios:**
- ‚úÖ Estrutura React correta
- ‚úÖ Tipagem de props/estado
- ‚úÖ Valida√ß√£o funcional
- ‚úÖ Loading state
- ‚úÖ Error handling

---

### üß™ Teste 4: Debug de C√≥digo (Intermedi√°rio)

**Tempo estimado:** 2-3 minutos

**Prompt (Qwen):**
```

Encontre e corrija os bugs neste c√≥digo:

```typescript
async function fetchUsers() {
  const response = await fetch('/api/users');
  const users = response.json();

  users.forEach((user) => {
    if ((user.role = 'admin')) {
      console.log('Admin found:', user.name);
    }
  });

  return users;
}
```

Liste todos os bugs encontrados e explique cada corre√ß√£o.
Arquivo: src/fetchUsers.ts

```

**Bugs para encontrar:**
1. `response.json()` precisa de await
2. `=` ao inv√©s de `===` (atribui√ß√£o vs compara√ß√£o)
3. Falta tratamento de erro
4. Falta verifica√ß√£o de response.ok

---

### üß™ Teste 5: API REST (Avan√ßado)

**Tempo estimado:** 5-8 minutos

**Prompt (Qwen):**
```

Crie uma API REST completa para gerenciamento de tarefas (TODO).

Requisitos:

1. Node.js + Express + TypeScript
2. CRUD completo (Create, Read, Update, Delete)
3. Valida√ß√£o com Zod
4. Persist√™ncia em mem√≥ria (array)
5. Rotas: GET, POST, PUT, DELETE
6. Tratamento de erros
7. Status codes corretos

Arquivo: src/api/todo.ts

```

**Prompt (Claude):**
```

Create a complete REST API for task management (TODO).

Requirements:

1. Node.js + Express + TypeScript
2. Full CRUD (Create, Read, Update, Delete)
3. Validation with Zod
4. In-memory persistence (array)
5. Routes: GET, POST, PUT, DELETE
6. Error handling
7. Correct status codes

File: src/api/todo.ts

```

**Crit√©rios:**
- ‚úÖ Estrutura Express correta
- ‚úÖ Tipagem TypeScript
- ‚úÖ Valida√ß√£o Zod
- ‚úÖ CRUD completo
- ‚úÖ Error handling

---

## Executando os Testes

### üìã Checklist de Execu√ß√£o

#### Para Cada Teste:

```

[ ] 1. Limpar diret√≥rio (git clean -fdx)
[ ] 2. Executar no Qwen (node dist/cli.js)
[ ] 3. Anotar tempo de resposta
[ ] 4. Salvar resultado (cp -r src qwen-test-XX)
[ ] 5. Limpar diret√≥rio
[ ] 6. Executar no claude
[ ] 7. Anotar tempo de resposta
[ ] 8. Salvar resultado (cp -r src claude-test-XX)
[ ] 9. Preencher planilha de resultados

````

### üõ†Ô∏è Comandos √öteis

#### Medir Tempo com Precis√£o

```bash
# Usar time do bash
time node dist/cli.js "<prompt>"

# Output exemplo:
# node dist/cli.js "<prompt>"  2.34s user 0.45s system 85% cpu 3.271 total
````

#### Comparar Resultados

```bash
# Comparar estrutura de arquivos
diff qwen-test-01 claude-test-01

# Comparar linhas de c√≥digo
wc -l qwen-test-01/src/*.ts claude-test-01/src/*.ts

# Ver diferen√ßas em arquivo espec√≠fico
diff qwen-test-01/src/validateEmail.ts claude-test-01/src/validateEmail.ts
```

#### Salvar Outputs

```bash
# Salvar output completo do Qwen
node dist/cli.js "<prompt>" 2>&1 | tee qwen-output-test-01.txt

# Salvar output completo do Claude
claude "<prompt>" 2>&1 | tee claude-output-test-01.txt
```

### üìù Dicas de Execu√ß√£o

1. **Execute em sequ√™ncia** - N√£o alterne entre testes
2. **Mantenha o contexto limpo** - Sempre use `git clean -fdx`
3. **Anote tudo** - Tempo, qualidade percebida, issues
4. **Use o mesmo prompt** - Traduza apenas o necess√°rio
5. **N√£o edite resultados** - Avalie como foram gerados
6. **Build antes de testar** - Sempre rode `npm run build` antes dos testes

---

## M√©tricas de Avalia√ß√£o

### üìä Planilha de Resultados

Copie e preencha esta planilha para cada teste:

```markdown
| Teste | CLI          | Tempo (s) | Input Tokens | Output Tokens | Total Tokens | Custo Estimado | Corre√ß√£o (0-10) | Qualidade (0-10) | UX (0-10) | Score Final |
| ----- | ------------ | --------- | ------------ | ------------- | ------------ | -------------- | --------------- | ---------------- | --------- | ----------- |
| 1     | Qwen (build) |           |              |               |              | $              |                 |                  |           |             |
| 1     | Claude       |           |              |               |              | $              |                 |                  |           |             |
| 2     | Qwen (build) |           |              |               |              | $              |                 |                  |           |             |
| 2     | Claude       |           |              |               |              | $              |                 |                  |           |             |
| 3     | Qwen (build) |           |              |               |              | $              |                 |                  |           |             |
| 3     | Claude       |           |              |               |              | $              |                 |                  |           |             |
| 4     | Qwen (build) |           |              |               |              | $              |                 |                  |           |             |
| 4     | Claude       |           |              |               |              | $              |                 |                  |           |             |
| 5     | Qwen (build) |           |              |               |              | $              |                 |                  |           |             |
| 5     | Claude       |           |              |               |              | $              |                 |                  |           |             |
```

### üìà M√©tricas Agregadas

```markdown
| M√©trica              | Qwen (build) | Claude  | Diferen√ßa |
| -------------------- | ------------ | ------- | --------- |
| Tempo M√©dio          | 0.0s         | 0.0s    | -         |
| Total Tokens (m√©dio) | 0            | 0       | -         |
| Custo M√©dio          | $0.00        | $0.00   | -         |
| Corre√ß√£o M√©dia       | 0.0          | 0.0     | -         |
| Qualidade M√©dia      | 0.0          | 0.0     | -         |
| **Score Final**      | **0.0**      | **0.0** | **-**     |
```

### üìà Como Calcular o Score Final

```
Score = (Corre√ß√£o √ó 0.35) + (Qualidade √ó 0.35) + (Tempo Normalizado √ó 0.15) + (UX √ó 0.15)

Tempo Normalizado = max(0, 10 - (tempo_segundos / 5))

Exemplo:
- Corre√ß√£o: 8
- Qualidade: 7
- Tempo: 10s ‚Üí Tempo Normalizado = 10 - (10/5) = 8
- UX: 9

Score = (8 √ó 0.35) + (7 √ó 0.35) + (8 √ó 0.15) + (9 √ó 0.15)
Score = 2.8 + 2.45 + 1.2 + 1.35 = 7.8
```

### üìù Avalia√ß√£o Subjetiva

Al√©m dos n√∫meros, registre impress√µes:

```markdown
## Observa√ß√µes - Teste 1

### Qwen

**Pontos fortes:**

- Gerou c√≥digo funcional
- Boa documenta√ß√£o

**Pontos fracos:**

- Mais lento que o esperado
- C√≥digo verboso

### Claude

**Pontos fortes:**

- Muito r√°pido
- C√≥digo conciso

**Pontos fracos:**

- Falta tratamento de erro

### Vencedor: Claude (por velocidade)
```

---

## Planilha de Resultados

### üìã Template para Copiar

```markdown
# Resultados do Benchmark

**Data:** 2026-02-28
**Vers√£o Qwen:** build local (npm run build)
**Vers√£o Claude:** latest
**Pre√ßos usados:**

- Qwen: $0.0001/1K input, $0.0003/1K output
- Claude: $0.0003/1K input, $0.0015/1K output

## Resumo

| M√©trica               | Qwen (build) | Claude  | Diferen√ßa |
| --------------------- | ------------ | ------- | --------- |
| Tempo M√©dio           | 0.0s         | 0.0s    | -         |
| Input Tokens (m√©dio)  | 0            | 0       | -         |
| Output Tokens (m√©dio) | 0            | 0       | -         |
| Total Tokens (m√©dio)  | 0            | 0       | -         |
| Custo M√©dio           | $0.00        | $0.00   | -         |
| Corre√ß√£o M√©dia        | 0.0          | 0.0     | -         |
| Qualidade M√©dia       | 0.0          | 0.0     | -         |
| UX M√©dio              | 0.0          | 0.0     | -         |
| **Score Final**       | **0.0**      | **0.0** | **-**     |

## Detalhe por Teste

### Teste 1: Valida√ß√£o de Email

| CLI          | Tempo | Input | Output | Total | Custo | Corre√ß√£o | Qualidade | UX  | Score |
| ------------ | ----- | ----- | ------ | ----- | ----- | -------- | --------- | --- | ----- |
| Qwen (build) |       |       |        |       | $     |          |           |     |       |
| Claude       |       |       |        |       | $     |          |           |     |       |

**Observa√ß√µes:**

- Qwen:
- Claude:

**Vencedor:**

---

### Teste 2: Refatora√ß√£o

| CLI          | Tempo | Input | Output | Total | Custo | Corre√ß√£o | Qualidade | UX  | Score |
| ------------ | ----- | ----- | ------ | ----- | ----- | -------- | --------- | --- | ----- |
| Qwen (build) |       |       |        |       | $     |          |           |     |       |
| Claude       |       |       |        |       | $     |          |           |     |       |

**Observa√ß√µes:**

**Vencedor:**

---

### Teste 3: Componente React

| CLI          | Tempo | Input | Output | Total | Custo | Corre√ß√£o | Qualidade | UX  | Score |
| ------------ | ----- | ----- | ------ | ----- | ----- | -------- | --------- | --- | ----- |
| Qwen (build) |       |       |        |       | $     |          |           |     |       |
| Claude       |       |       |        |       | $     |          |           |     |       |

**Observa√ß√µes:**

**Vencedor:**

---

### Teste 4: Debug de C√≥digo

| CLI          | Tempo | Input | Output | Total | Custo | Corre√ß√£o | Qualidade | UX  | Score |
| ------------ | ----- | ----- | ------ | ----- | ----- | -------- | --------- | --- | ----- |
| Qwen (build) |       |       |        |       | $     |          |           |     |       |
| Claude       |       |       |        |       | $     |          |           |     |       |

**Observa√ß√µes:**

**Vencedor:**

---

### Teste 5: API REST

| CLI          | Tempo | Input | Output | Total | Custo | Corre√ß√£o | Qualidade | UX  | Score |
| ------------ | ----- | ----- | ------ | ----- | ----- | -------- | --------- | --- | ----- |
| Qwen (build) |       |       |        |       | $     |          |           |     |       |
| Claude       |       |       |        |       | $     |          |           |     |       |

**Observa√ß√µes:**

**Vencedor:**

---

## Comparativo de Tokens

| M√©trica      | Qwen (build) | Claude | Diferen√ßa | % Economia |
| ------------ | ------------ | ------ | --------- | ---------- |
| Total Tokens | 0            | 0      | 0         | -          |
| Custo Total  | $0.00        | $0.00  | $0.00     | -          |
| Tokens/Teste | 0            | 0      | 0         | -          |

---

## Conclus√£o

**Vencedor Geral:**

**Motivo:**

**A√ß√µes de Melhoria para Qwen:**

1.
2.
3.
```

---

## An√°lise Comparativa

### üîç Interpretando Resultados

#### Diferen√ßas Significativas

| Diferen√ßa | Interpreta√ß√£o                     |
| --------- | --------------------------------- |
| > 20%     | Diferen√ßa significativa           |
| 10-20%    | Diferen√ßa moderada                |
| < 10%     | Diferen√ßa marginal/empate t√©cnico |

#### Cen√°rios Comuns

**Qwen mais lento, mesma qualidade:**

- Problema de infraestrutura/otimiza√ß√£o
- A√ß√£o: Otimizar streaming, reduzir overhead

**Qwen mesma velocidade, qualidade inferior:**

- Problema de modelo/prompt engineering
- A√ß√£o: Melhorar system prompt, few-shot examples

**Qwen perde em UX:**

- Problema de ergonomia/fluxo
- A√ß√£o: Melhorar mensagens, feedback visual

### üìä Exemplo Preenchido

```markdown
# Resultados do Benchmark

**Data:** 2026-02-28
**Vers√£o Qwen:** build local (dev)
**Vers√£o Claude:** 1.0.0
**Pre√ßos usados:**

- Qwen: $0.0001/1K input, $0.0003/1K output
- Claude: $0.0003/1K input, $0.0015/1K output

## Resumo

| M√©trica               | Qwen (build) | Claude   | Diferen√ßa |
| --------------------- | ------------ | -------- | --------- |
| Tempo M√©dio           | 12.5s        | 8.2s     | +52% Qwen |
| Input Tokens (m√©dio)  | 350          | 320      | +9% Qwen  |
| Output Tokens (m√©dio) | 450          | 400      | +12% Qwen |
| Total Tokens (m√©dio)  | 800          | 720      | +11% Qwen |
| Custo M√©dio           | $0.00017     | $0.00070 | -76% Qwen |
| Corre√ß√£o M√©dia        | 8.2          | 8.8      | -0.6      |
| Qualidade M√©dia       | 7.8          | 8.5      | -0.7      |
| UX M√©dio              | 8.0          | 8.5      | -0.5      |
| **Score Final**       | **8.0**      | **8.6**  | **-0.6**  |

## Conclus√£o

**Vencedor Geral:** Claude Code (qualidade) mas Qwen economiza 76% em custos

**Motivo:**

- Claude: 52% mais r√°pido, qualidade superior
- Qwen: Custo 76% menor, qualidade aceit√°vel

**A√ß√µes de Melhoria para Qwen:**

1. Otimizar first token time (infraestrutura)
2. Melhorar system prompt para qualidade
3. Manter vantagem de custo
```

### üí∞ Como Calcular Custos

#### F√≥rmula

```
Custo = (Input Tokens / 1000 √ó Pre√ßo Input) + (Output Tokens / 1000 √ó Pre√ßo Output)
```

#### Pre√ßos de Refer√™ncia (fevereiro 2026)

| Modelo/Provider       | Input (por 1K) | Output (por 1K) |
| --------------------- | -------------- | --------------- |
| **Qwen (Alibaba)**    | $0.0001        | $0.0003         |
| **Claude 3.5 Sonnet** | $0.0003        | $0.0015         |
| **Claude 3.5 Haiku**  | $0.00008       | $0.0004         |
| **GPT-4o**            | $0.0025        | $0.0075         |
| **GPT-4o-mini**       | $0.00015       | $0.0006         |

#### Script de C√°lculo

```bash
#!/bin/bash
# calculate-cost.sh

INPUT_TOKENS=$1
OUTPUT_TOKENS=$2
PRICE_INPUT=${3:-0.0001}   # Default: pre√ßo Qwen
PRICE_OUTPUT=${4:-0.0003}  # Default: pre√ßo Qwen

# Calcular custo
COST=$(echo "scale=6; ($INPUT_TOKENS / 1000 * $PRICE_INPUT) + ($OUTPUT_TOKENS / 1000 * $PRICE_OUTPUT)" | bc)

echo "Input: $INPUT_TOKENS tokens"
echo "Output: $OUTPUT_TOKENS tokens"
echo "Custo: \$${COST}"
```

#### Uso

```bash
# Calcular custo Qwen
./calculate-cost.sh 350 450 0.0001 0.0003
# Output: Custo: $0.000170

# Calcular custo Claude
./calculate-cost.sh 320 400 0.0003 0.0015
# Output: Custo: $0.000696
```

### üéØ Pr√≥ximos Passos

#### Se Qwen Perdeu

1. **Identifique gaps espec√≠ficos**
   - Performance? ‚Üí Otimizar infra
   - Qualidade? ‚Üí Melhorar prompts
   - UX? ‚Üí Melhorar interface

2. **Priorize melhorias**
   - Impacto alto + esfor√ßo baixo primeiro
   - Quick wins para motivar time

3. **Re-teste ap√≥s melhorias**
   - Benchmark cont√≠nuo
   - Acompanhe progresso

#### Se Qwen Ganhou/Empatou

1. **Valide resultados**
   - Mais testes, mais amostras
   - Diferentes tipos de projeto

2. **Documente aprendizados**
   - O que funcionou bem?
   - O que pode melhorar ainda mais?

3. **Mantenha qualidade**
   - Benchmark regressivo
   - N√£o quebrar o que funciona

---

## üìö Refer√™ncias

- [Claude Code CLI](https://github.com/anthropics/claude-code)
- [Qwen Code CLI](https://github.com/qwen-code/qwen-code)
- [LMSys Chatbot Arena](https://chat.lmsys.org/)
- [BigCode Bench](https://huggingface.co/bigcode)
- [OpenAI Pricing](https://openai.com/pricing)
- [Anthropic Pricing](https://www.anthropic.com/pricing)
- [Alibaba Cloud Pricing](https://www.alibabacloud.com/product/intelligent-computing/pricing)

---

**Documento criado:** 2026-02-28
**√öltima atualiza√ß√£o:** 2026-02-28
**Vers√£o:** 2.0.0 - Benchmark: Qwen Code (aplica√ß√£o buildada - node dist/cli.js) vs Claude Code CLI
**M√©tricas principais:** Tempo, Tokens (input/output), Custo estimado, Qualidade de c√≥digo
